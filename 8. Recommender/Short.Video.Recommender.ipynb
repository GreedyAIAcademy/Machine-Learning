{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 短视频推荐系统\n",
    "\n",
    "## 使用矩阵分解, 根据用户给短视频的评分数据, 做一个千人千面的个性化推荐系统\n",
    "### 需要安装推荐系统库surprise, 使用如下命令安装: pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 nunpy 和 surprise 辅助库\n",
    "import numpy as np\n",
    "import surprise  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise库本身没有提供纯粹的矩阵分解的算法, 在这里我们自己实现了基于Alternating Least Squares的矩阵分解, 使用梯度下降法优化\n",
    "### 矩阵分解类MatrixFactorization继承了surprise.AlgoBase, 方便我们使用surpise库提供的其它功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(surprise.AlgoBase):\n",
    "    '''基于矩阵分解的推荐.'''\n",
    "    \n",
    "    def __init__(self, learning_rate, n_epochs, n_factors, lmd):\n",
    "        \n",
    "        self.lr = learning_rate  # 梯度下降法的学习率\n",
    "        self.n_epochs = n_epochs  # 梯度下降法的迭代次数\n",
    "        self.n_factors = n_factors  # 分解的矩阵的秩(rank)\n",
    "        self.lmd = lmd # 防止过拟合的正则化的强度\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        '''通过梯度下降法训练, 得到所有 u_i 和 p_j 的值'''\n",
    "        \n",
    "        print('Fitting data with SGD...')\n",
    "        \n",
    "        # 随机初始化 user 和 item 矩阵.\n",
    "        u = np.random.normal(0, .1, (trainset.n_users, self.n_factors))\n",
    "        p = np.random.normal(0, .1, (trainset.n_items, self.n_factors))\n",
    "        \n",
    "        # 梯度下降法\n",
    "        for _ in range(self.n_epochs):\n",
    "            for i, j, r_ij in trainset.all_ratings():\n",
    "                err = r_ij - np.dot(u[i], p[j])\n",
    "                # 利用梯度调整 u_i 和 p_j\n",
    "                u[i] -= -self.lr * err * p[j] + self.lr * self.lmd * u[i]\n",
    "                p[j] -= -self.lr * err * u[i] + self.lr * self.lmd * p[j]\n",
    "                # 注意: 修正 p_j 时, 按照严格定义, 我们应该使用 u_i 修正之前的值, 但是实际上差别微乎其微\n",
    "        \n",
    "        self.u, self.p = u, p\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, i, j):\n",
    "        '''预测 user i 对 item j 的评分.'''\n",
    "        \n",
    "        # 如果用户 i 和物品 j 是已知的值, 返回 u_i 和 p_j 的点积\n",
    "        # 否则使用全局平均评分rating值(cold start 冷启动问题)\n",
    "        if self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
    "            return np.dot(self.u[i], self.p[j])\n",
    "        else:\n",
    "            return self.trainset.global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演示如何调用以上定义的矩阵分解类实现短视频的推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# 数据文件\n",
    "file_path = os.path.expanduser('./ml-100k/u.data')\n",
    "\n",
    "# 数据文件的格式如下:\n",
    "# 'user item rating timestamp', 使用制表符 '\\t' 分割, rating值在1-5之间.\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t', rating_scale=(1, 5))\n",
    "data = Dataset.load_from_file(file_path, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data with SGD...\n",
      "MAE:  0.7871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7871327139440717"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据随机分为训练和测试数据集\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "# 初始化以上定义的矩阵分解类.\n",
    "algo = MatrixFactorization(learning_rate=.005, n_epochs=60, n_factors=2, lmd = 0.2)\n",
    "\n",
    "# 训练\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 预测\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# 计算平均绝对误差\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MAE:  0.7827\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7827160139309475"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 surpise 内建的基于最近邻的方法做比较\n",
    "algo = surprise.KNNBasic()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.7451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7450633876817936"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 surpise 内建的基于 SVD 的方法做比较\n",
    "algo = surprise.SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
