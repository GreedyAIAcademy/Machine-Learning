{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 书籍商品推荐系统\n",
    "\n",
    "## 使用矩阵分解, 根据用户给书籍商品的评分数据, 做一个千人千面的个性化推荐系统\n",
    "### 需要安装推荐系统库surprise, 使用如下命令安装: pip install scikit-surprise\n",
    "## 需要自己补全带<span style=\"color:red\">TODO</span>部分的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 nunpy 和 surprise 辅助库\n",
    "import numpy as np\n",
    "import surprise  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise库本身没有提供纯粹的矩阵分解的算法, 在这里我们自己实现了基于Alternating Least Squares的矩阵分解, 使用梯度下降法优化\n",
    "### 矩阵分解类MatrixFactorization继承了surprise.AlgoBase, 方便我们使用surpise库提供的其它功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(surprise.AlgoBase):\n",
    "    '''基于矩阵分解的推荐.'''\n",
    "    \n",
    "    def __init__(self, learning_rate, n_epochs, n_factors, lmd):\n",
    "        \n",
    "        self.lr = learning_rate  # 梯度下降法的学习率\n",
    "        self.n_epochs = n_epochs  # 梯度下降法的迭代次数\n",
    "        self.n_factors = n_factors  # 分解的矩阵的秩(rank)\n",
    "        self.lmd = lmd # 防止过拟合的正则化的强度\n",
    "        \n",
    "    def fit(self, trainset):\n",
    "        '''通过梯度下降法训练, 得到所有 u_i 和 p_j 的值'''\n",
    "        \n",
    "        print('Fitting data with SGD...')\n",
    "        \n",
    "        # 随机初始化 user 和 item 矩阵.\n",
    "        u = np.random.normal(0, .1, (trainset.n_users, self.n_factors))\n",
    "        p = np.random.normal(0, .1, (trainset.n_items, self.n_factors))\n",
    "        \n",
    "        # 梯度下降法\n",
    "        for _ in range(self.n_epochs):\n",
    "            for i, j, r_ij in trainset.all_ratings():\n",
    "                err = r_ij - np.dot(u[i], p[j])\n",
    "                TODO\n",
    "                # 利用梯度调整 u_i 和 p_j\n",
    "                # 注意: 修正 p_j 时, 安装严格定义, 我们应该使用 u_i 修正之前的值, 但是实际上差别微乎其微\n",
    "        \n",
    "        self.u, self.p = u, p\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def estimate(self, i, j):\n",
    "        '''预测 user i 对 item j 的评分.'''\n",
    "        \n",
    "        # 如果用户 i 和物品 j 是已知的值, 返回 u_i 和 p_j 的点击\n",
    "        # 否则使用全局平均评分rating值(cold start 冷启动问题)\n",
    "        if self.trainset.knows_user(i) and self.trainset.knows_item(j):\n",
    "            TODO\n",
    "            # 返回 u_i 和 p_j 的点击\n",
    "        else:\n",
    "            TODO\n",
    "            # 返回 全局平均评分rating值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演示如何调用以上定义的矩阵分解类实现书籍商品的推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "file_path = os.path.expanduser('./book_crossing/book_ratings.dat')\n",
    "\n",
    "TODO\n",
    "# 创建 reader 对象\n",
    "\n",
    "data = Dataset.load_from_file(file_path, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting data with SGD...\n",
      "MAE:  1.3518\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3517903389238524"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将数据随机分为训练和测试数据集\n",
    "trainset, testset = train_test_split(data, test_size=.25)\n",
    "\n",
    "TODO\n",
    "# 初始化以上定义的矩阵分解类.\n",
    "\n",
    "TODO\n",
    "# 训练\n",
    "\n",
    "TODO\n",
    "# 预测\n",
    "\n",
    "TODO\n",
    "# 计算平均绝对误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MAE:  1.4289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4288857409716478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 surpise 内建的基于最近邻的方法做比较\n",
    "algo = surprise.KNNBasic()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  1.1411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.141127493999726"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 surpise 内建的基于 SVD 的方法做比较\n",
    "algo = surprise.SVD()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
